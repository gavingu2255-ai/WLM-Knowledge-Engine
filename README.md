# WLMâ€‘Knowledgeâ€‘Engine  
**Turn token soup â†’ dimensional structure â†’ reasoningâ€‘ready knowledge graphs**

The **WLMâ€‘Knowledgeâ€‘Engine** is the **knowledge structuring layer** of the WLM ecosystem.  
It transforms unstructured text into **dimensional knowledge structures** and then into  
**reasoningâ€‘ready knowledge graphs** that AI systems can actually *understand* and *use*.

This is the **fifth major layer** of WLM:

1. SLPâ€‘Worldâ€‘Interpreter â€” Language â†’ Structure  
2. WLMâ€‘Worldâ€‘Modelâ€‘Interpreter â€” World Model â†’ Structure  
3. WLMâ€‘Agentâ€‘Behavior â€” Structure â†’ Behavior  
4. WLMâ€‘Personaâ€‘Engine â€” Structure â†’ Identity  
5. **WLMâ€‘Knowledgeâ€‘Engine â€” Structure â†’ Knowledge** â† *this repo*

It provides the missing link between **text** and **true understanding**:

> **Structure â†’ Knowledge â†’ Reasoning â†’ World**

---

## âœ¨ Why this exists

LLMs do not â€œunderstandâ€ knowledge.  
They interpolate token patterns.  
They memorize embeddings.  
They regurgitate correlations.

This leads to:

- hallucinations  
- contradictions  
- shallow reasoning  
- no global consistency  
- no causal structure  
- no dimensional grounding  

The WLMâ€‘Knowledgeâ€‘Engine fixes this by converting text into:

- **dimensional structures**  
- **entity graphs**  
- **causal relations**  
- **temporal sequences**  
- **physical constraints**  
- **worldâ€‘consistent knowledge graphs**  

This is **knowledge as structure**, not as embeddings.

---

## âœ¨ Features

### **1. Dimensional Knowledge Extraction**
Extracts knowledge along WLMâ€™s four core dimensions:

- **Spatial** â€” locations, topology, containment  
- **Temporal** â€” sequences, durations, dependencies  
- **Physical** â€” forces, constraints, affordances  
- **Causal** â€” preconditions, effects, mechanisms  

### **2. Knowledge Graph Construction**
Builds a **deterministic, interpretable knowledge graph**:

- nodes = entities  
- edges = dimensional relations  
- closures = predicted future states  
- tensions = contradictions or missing links  

### **3. Contradiction Detection**
Detects:

- logical conflicts  
- causal impossibilities  
- temporal inconsistencies  
- spatial contradictions  

### **4. Reasoningâ€‘Ready Output**
Produces a graph that can be used by:

- agents  
- planners  
- simulators  
- reasoning engines  
- multiâ€‘agent systems  

### **5. Deterministic Pipeline**
Same text â†’ same structure â†’ same knowledge graph.

---

## ğŸš€ Quickstart

### **Install**

```bash
pip install wlm-knowledge-engine
```

### **Use**

```python
from wlm_knowledge_engine import extract_knowledge

kg = extract_knowledge("The Earth orbits the Sun once every 365 days.")
print(kg)
```

### **Output (MVP)**

```
KnowledgeGraph {
  entities: ["Earth", "Sun"]
  relations: [
    orbit(Earth, Sun),
    period(Earth, 365 days)
  ]
  dimensions: { ... }
  tensions: []
  closures: []
}
```

---

## ğŸ§  How it works

The engine performs three steps:

### **1. Text â†’ Dimensional Structure**
Extracts:

- entities  
- relations  
- events  
- causal links  
- temporal sequences  
- physical constraints  

### **2. Structure â†’ Knowledge Graph**
Normalizes and merges:

- nodes  
- edges  
- dimensional annotations  
- closures  
- tensions  

### **3. Knowledge Graph â†’ Reasoning Substrate**
Produces a graph that can be used for:

- causal reasoning  
- temporal reasoning  
- spatial reasoning  
- multiâ€‘agent coordination  
- world model updates  

---

## ğŸ“¦ API

### `extract_knowledge(text: str) â†’ dict`

```python
def extract_knowledge(text: str) -> dict:
    """
    Convert raw text into a dimensional knowledge graph.
    """
```

### KnowledgeGraph structure (MVP)

```json
{
  "entities": [],
  "relations": [],
  "dimensions": {},
  "tensions": [],
  "closures": []
}
```

---

## ğŸ“˜ Examples

### Example: Simple Fact

**Input**

```
Water boils at 100Â°C.
```

**Output**

```
entity: Water
relation: boils_at(Water, 100Â°C)
dimension: physical
```

---

## ğŸ— Repository Structure

```
wlm-knowledge-engine/
â”‚
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ setup.cfg
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ wlm_knowledge_engine/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ api.py
â”‚       â”œâ”€â”€ extractor.py
â”‚       â”œâ”€â”€ dimension_engine.py
â”‚       â”œâ”€â”€ graph_builder.py
â”‚       â”œâ”€â”€ tension_detector.py
â”‚       â”œâ”€â”€ closure_predictor.py
â”‚       â””â”€â”€ cli.py
â”‚
â”œâ”€â”€ examples/
â”‚   â”œâ”€â”€ simple_fact.md
â”‚   â”œâ”€â”€ causal_chain.md
â”‚   â””â”€â”€ temporal_sequence.md
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_extractor.py
â”‚   â”œâ”€â”€ test_graph_builder.py
â”‚   â”œâ”€â”€ test_dimension_engine.py
â”‚   â””â”€â”€ test_end_to_end.py
â”‚
â””â”€â”€ docs/
    â”œâ”€â”€ overview.md
    â”œâ”€â”€ knowledge-rules.md
    â”œâ”€â”€ api.md
    â””â”€â”€ roadmap.md
```

---

## ğŸ“„ License

MIT License  
Copyright (c) 2026  
**Wujie Gu**

---

## ğŸ§© Summary

The **WLMâ€‘Knowledgeâ€‘Engine** is the structural knowledge layer of the WLM ecosystem.  
It turns text into **dimensional structure**, then into **reasoningâ€‘ready knowledge graphs**.

It enables:

- real understanding  
- causal reasoning  
- temporal reasoning  
- spatial reasoning  
- consistent world models  
- agents that actually know things  

A foundational component of the **WLM knowledge stack**.
